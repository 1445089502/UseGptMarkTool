import os
import json
import torch
import tkinter as tk
from tkinter import filedialog
from tqdm import tqdm
from concurrent.futures import ThreadPoolExecutor
from torchvision import transforms
from torchvision.io import read_image
from transformers import AutoModelForImageClassification
from torch.amp import autocast
from pathlib import Path
import shutil
import warnings

warnings.filterwarnings("ignore", category=UserWarning)

# ==== æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå›ºå®šåœ¨è„šæœ¬åŒç›®å½•ï¼‰ ====
BASE_DIR         = Path(__file__).parent
success_log_path = BASE_DIR / "success_log.txt"
failed_log_path  = BASE_DIR / "failed_log.txt"

# ==== è¯»å–å·²å¤„ç†è¿‡çš„ç¼“å­˜ï¼ˆåªåšä¸€æ¬¡ I/Oï¼Œç»Ÿä¸€å¤§å°å†™ & è§„èŒƒåˆ†éš”ç¬¦ï¼‰ ====
processed_cache = set()
if success_log_path.exists():
    for line in success_log_path.read_text(encoding="utf-8", errors="ignore").splitlines():
        p = line.strip()
        if not p:
            continue
        norm = os.path.normcase(os.path.normpath(p))
        processed_cache.add(norm)

# ==== åˆå§‹åŒ–è®¾å¤‡ï¼Œä»…æ‰“å°ä¸€æ¬¡ ====
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("\nğŸš€ å½“å‰ä½¿ç”¨è®¾å¤‡ï¼š", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")

# ==== æ¨¡å‹åŠ è½½ä¸ warm-up ====
model_name = "Falconsai/nsfw_image_detection"
model = AutoModelForImageClassification.from_pretrained(model_name).eval().to(device)

image_size = getattr(model.config, "image_size", 224)
id2label   = getattr(model.config, "id2label", {0: "safe", 1: "nsfw"})

with torch.no_grad():
    dummy = torch.rand(1, 3, image_size, image_size).to(device)
    _ = model(pixel_values=dummy)

# ==== å‚æ•°é…ç½® ====
valid_exts       = (".jpg", ".jpeg", ".png", ".webp", ".gif")
batch_size       = 32
max_workers_load = 4
max_workers_scan = 8

# ==== GPU ç«¯é¢„å¤„ç†æµæ°´çº¿ ====
transform_gpu = transforms.Compose([
    transforms.Resize([image_size, image_size]),
    transforms.ConvertImageDtype(torch.float32),
    transforms.Normalize(mean=[0.5, 0.5, 0.5],
                         std =[0.5, 0.5, 0.5]),
])

write_pool = ThreadPoolExecutor(max_workers=4)

# ==== æ‰«æ .info æ–‡ä»¶å¤¹ï¼Œå–ç¬¬ä¸€å¼ ç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡è·¯å¾„ ====
def find_first_image(folder_path: str) -> str | None:
    for entry in os.scandir(folder_path):
        if not entry.is_file():
            continue
        name = entry.name.lower()
        if name.endswith(valid_exts) and "thumbnail" not in name:
            return entry.path
    return None

def scan_info_folders(root_dir: str) -> list[str]:
    # é˜¶æ®µ1ï¼šåˆ—å‡ºæ‰€æœ‰ä»¥ .info ç»“å°¾çš„å­ç›®å½•
    info_dirs = [
        entry.path for entry in os.scandir(root_dir)
        if entry.is_dir() and entry.name.endswith(".info")
    ]
    # é˜¶æ®µ2ï¼šå¹¶è¡ŒæŸ¥æ‰¾æ¯ä¸ªç›®å½•çš„ç¬¬ä¸€å¼ å›¾
    results = []
    with ThreadPoolExecutor(max_workers=max_workers_scan) as executor:
        for img_path in tqdm(
                executor.map(find_first_image, info_dirs),
                total=len(info_dirs),
                desc="æ‰«æ .info æ–‡ä»¶å¤¹",
                unit="dir",
        ):
            if img_path:
                results.append(img_path)
    return results

# ==== åŠ è½½å¹¶é¢„å¤„ç†å•å¼ å›¾ç‰‡ä¸º GPU Tensor ====
def load_image_tensor(image_path: Path):
    try:
        tensor = read_image(str(image_path))  # [C,H,W]
        c = tensor.shape[0]
        if c == 4:
            tensor = tensor[:3]
        elif c == 1:
            tensor = tensor.expand(3, -1, -1)
        elif c != 3:
            raise ValueError(f"Unsupported channel size: {c}")
        return transform_gpu(tensor).to(device)
    except Exception as e:
        print(f"[è·³è¿‡] è¯»å–å¤±è´¥ï¼š{image_path} -> {e}")
        failed_log_path.open("a", encoding="utf-8").write(f"{image_path}\n")
        return None

# ==== æ‰¹é‡æ¨ç† + å†™æ—¥å¿— / æ‰“æ ‡ç­¾ / è¾“å‡ºå›¾ç‰‡ ====
def process_batch(images, paths, mode, out_root=None):
    batch = torch.stack(images)
    torch.cuda.synchronize()
    with torch.no_grad(), autocast(device_type="cuda"):
        outputs = model(pixel_values=batch)
        probs   = torch.softmax(outputs.logits, dim=1)
        preds   = torch.argmax(probs, dim=1)
    torch.cuda.synchronize()

    with success_log_path.open("a", encoding="utf-8") as f_succ:
        for path_str, pred in zip(paths, preds):
            label = id2label[pred.item()]
            # å†™å…¥æ—¥å¿—æ—¶ä¹Ÿåªå†™åŸå§‹è·¯å¾„
            f_succ.write(f"{path_str}\n")
            if mode == "1":
                apply_eagle_tag(Path(path_str), label)
            else:
                save_to_output_folder(Path(path_str), label, out_root)

# ==== Eagle æ¨¡å¼ï¼šä¿®æ”¹ metadata.json ä¸­çš„ tags ====
metadata_cache = {}
def apply_eagle_tag(image_path: Path, label: str):
    meta_path = image_path.parent / "metadata.json"
    if not meta_path.exists():
        return
    try:
        if meta_path in metadata_cache:
            data = metadata_cache[meta_path]
        else:
            data = json.loads(meta_path.read_text(encoding="utf-8", errors="ignore"))
            metadata_cache[meta_path] = data

        tags = data.get("tags", [])
        if "è‰²æƒ…" in tags or "éè‰²æƒ…" in tags:
            return

        tags = [t for t in tags if t not in ("è‰²æƒ…", "éè‰²æƒ…")]
        tags.append("è‰²æƒ…" if label == "nsfw" else "éè‰²æƒ…")
        data["tags"] = tags
        meta_path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    except Exception as e:
        print(f"[å¤±è´¥] æ›´æ–° metadata: {meta_path} -> {e}")
        failed_log_path.open("a", encoding="utf-8").write(f"{meta_path}\n")

# ==== æ™®é€šæ¨¡å¼ï¼šå¼‚æ­¥å¤åˆ¶æ–‡ä»¶åˆ° output æ–‡ä»¶å¤¹ ====
def async_copy(src: Path, dst: str):
    try:
        shutil.copy(str(src), dst)
    except Exception as e:
        print(f"[å¤åˆ¶å¤±è´¥] {src} -> {e}")
        failed_log_path.open("a", encoding="utf-8").write(f"{src}\n")

def save_to_output_folder(image_path: Path, label: str, out_root: str):
    folder = os.path.join(out_root, "è‰²æƒ…" if label == "nsfw" else "éè‰²æƒ…")
    os.makedirs(folder, exist_ok=True)
    dst = os.path.join(folder, image_path.name)
    write_pool.submit(async_copy, image_path, dst)

# ==== ç”¨æˆ·äº¤äº’ï¼šé€‰æ‹©æ¨¡å¼ & ç›®å½• ====
def choose_mode():
    print("\nè¾“å…¥æ¨¡å¼ (1=Eagle, 2=æ™®é€š):", end="")
    while True:
        c = input().strip()
        if c in ("1", "2"):
            return c
        print("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1 æˆ– 2:", end="")

def choose_folder():
    root = tk.Tk()
    root.withdraw()
    d = filedialog.askdirectory(title="è¯·é€‰æ‹©è¦å¤„ç†çš„å›¾ç‰‡æ ¹ç›®å½•")
    if not d:
        print("æœªé€‰æ‹©æ–‡ä»¶å¤¹ï¼Œç¨‹åºé€€å‡ºã€‚")
        exit()
    return d

# ==== Eagle æ¨¡å¼ä¸»æµç¨‹ï¼šå…ˆè¿‡æ»¤å†è¿›åº¦æ¡ ====
def run_eagle_mode(root_dir: str):
    # 1) æ‰«ææ‰€æœ‰ .info é¦–å¼ å›¾
    info_images = scan_info_folders(root_dir)
    print(f"å…±å‘ç° {len(info_images)} å¼ å¾…å¤„ç†å›¾ç‰‡")

    # 2) åœ¨å†…å­˜ä¸­ä¸€æ¬¡æ€§è¿‡æ»¤å·²å¤„ç†è·¯å¾„ï¼ˆæ— é¢å¤– I/Oï¼‰
    filtered = [
        p for p in info_images
        if os.path.normcase(os.path.normpath(p)) not in processed_cache
    ]
    print(f"æ’é™¤å·²å¤„ç†åå‰©ä½™ {len(filtered)} å¼ å¾…å¤„ç†å›¾ç‰‡")

    # 3) æ‰¹é‡æ¨ç†
    batch_imgs, batch_paths = [], []
    for img_path_str in tqdm(filtered, desc="å¤„ç†è¿›åº¦", unit="img"):
        p = Path(img_path_str)
        tensor = load_image_tensor(p)
        if tensor is None:
            continue
        batch_imgs.append(tensor)
        batch_paths.append(str(p))
        if len(batch_imgs) >= batch_size:
            process_batch(batch_imgs, batch_paths, mode="1")
            batch_imgs, batch_paths = [], []
    if batch_imgs:
        process_batch(batch_imgs, batch_paths, mode="1")

# ==== æ™®é€šæ¨¡å¼ä¸»æµç¨‹ ====
def run_normal_mode(root_dir: str):
    out_root = os.path.join(root_dir, "output")
    os.makedirs(out_root, exist_ok=True)

    # æ”¶é›†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
    all_files = [
        Path(root_dir) / f for f in os.listdir(root_dir)
        if Path(root_dir, f).is_file() and f.lower().endswith(valid_exts)
    ]
    # å¹¶è¡ŒåŠ è½½é¢„å¤„ç†
    with ThreadPoolExecutor(max_workers=max_workers_load) as ex:
        results = list(ex.map(load_image_tensor, all_files))

    # è¿‡æ»¤å·²å¤„ç†
    valid = [
        (img, p) for img, p in zip(results, all_files)
        if img is not None and os.path.normcase(os.path.normpath(str(p))) not in processed_cache
    ]

    # åˆ† batch æ¨ç†
    for i in tqdm(range(0, len(valid), batch_size), desc="å¤„ç†è¿›åº¦", unit="batch"):
        batch = valid[i : i + batch_size]
        imgs, paths = zip(*batch)
        process_batch(imgs, paths, mode="2", out_root=out_root)

# ==== ç¨‹åºå…¥å£ ====
if __name__ == "__main__":
    mode      = choose_mode()
    input_dir = choose_folder()
    if mode == "1":
        run_eagle_mode(input_dir)
    else:
        run_normal_mode(input_dir)
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
